[agent]
  interval = "10s"
  round_interval = true
  flush_interval = "10s"
  precision = "1s"
  logfile = ""

[global_tags]
  host = "TankSC"

# -------- System metrics --------
[[inputs.cpu]]
  percpu = false
  totalcpu = true
  report_active = true

[[inputs.mem]]
[[inputs.swap]]

[[inputs.disk]]
  ignore_fs = ["tmpfs", "devtmpfs", "overlay", "squashfs"]

[[inputs.diskio]]
  skip_serial_number = true

[[inputs.net]]
  # collect all interfaces; or set: interfaces = ["eth0","wlan0"]

[[inputs.processes]]
[[inputs.kernel]]
[[inputs.netstat]]
[[inputs.temp]]

# waterproof sensors
#[[inputs.exec]]
#  commands = ["/bin/sh /home/TankSC/temp-monitor/read_ds18b20.sh"]
#  data_format = "influx"
#  timeout = "5s"
#  interval = "5s"

# -------- Cloud-thinning pipeline --------
# 1) Clone ONLY the metrics we want to send to Grafana Cloud
[[processors.clone]]
  # Send only these measurements into the cloud path
  namepass = ["cpu", "mem", "disk", "temp"]
  [processors.clone.tags]
    route = "cloud"

# 2) Downsample the cloud clone to 1-minute means (drop 10s originals)
[[aggregators.basicstats]]
  # operate only on the cloned path
  tagpass = { route = ["cloud"] }
  period = "60s"
  drop_original = true
  # keep it lean: just means
  stats = ["mean"]


# -------- Output to InfluxDB v2 (HARDCODED) --------
[[outputs.influxdb_v2]]
  urls = ["http://influxdb:8086"]
  # OPTION A (hardcode token inline):
  token = "_ptWem9Opxqah4i-fvpzQKFN0nvkD1Y_BR9YxYP2GlUycEZ3Ad5TOM8jH6I_xlCi8KbnY1ppUGxrYI76C4SKtg=="

  # OPTION B (if you prefer a file, uncomment next 2 lines and remove 'token' above):
  # token_file = "/run/secrets/influx.token"

  organization = "home"
  bucket = "temps"
  # Don't store the cloud clone here (local keeps the full-res stream)
  tagdrop = { route = ["cloud"] }

# --- ALSO send to Grafana Cloud (Prometheus remote_write) ---
#[[outputs.http]]
  # Replace with your Grafana Cloud Metrics endpoint
# you wish hehe
